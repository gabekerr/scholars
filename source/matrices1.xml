<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-matrices1">
    <title>Matrices I</title>
    <p>Before discussing the abstract viewpoint of real and complex vector spaces, we will become acquainted with the central computational tool of the subject - matrices. Our number system will be labelled <m>K</m>, but for us <m>K</m> will either be <m>\mathbb{R}</m> or <m>\mathbb{C}</m>.</p>

    <definition xml:id="def-matrix">
            <notation>
                <usage><m>A = (a_{ij})</m></usage>
                <description>an <m>m \times n</m> matrix</description>
            </notation>
            <statement>
                <p>
                    For positive integers <m>m, n</m>, an <m>\mathbf{m \times n}</m> <term>matrix</term> is a rectangular array
                    <men xml:id="eq-matrices">  A = \left[ \begin{matrix} a_{11} \amp a_{12} \amp \cdots \amp a_{1n} \\ a_{21} \amp a_{22} \amp \cdots \amp a_{2n} \\ \vdots \amp \ddots \amp \amp \vdots \\ a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn} \end{matrix} \right] 
                    </men> 
                    For a given matrix <m>A</m>, call <m>a_{ij}</m> the <m>(i,j)</m>-th entry of the matrix and write <m>A = (a_{ij})</m> as shorthand to denote <m>A</m>. The <term>size</term> of <m>A</m> is <m>m \times n</m> where <m>m</m> is the number of rows and <m>n</m> the number of columns.
                </p>
            </statement>
    </definition>

    <p>The quanitites <m>a_{ij}</m> can be numbers or functions; anything where all of our rules of arithmetic from <xref ref="sec-arithmetic" /> hold. For then we can add two matrices of the same size by adding each entry of one to the corresponding entry of the other. With formulas, if  
    <me>
        A =  \left[ \begin{matrix} a_{11} \amp a_{12} \amp \cdots \amp a_{1n} \\ a_{21} \amp a_{22} \amp \cdots \amp a_{2n} \\ \vdots \amp \ddots \amp \amp \vdots \\ a_{m1} \amp a_{m2} \amp \cdots \amp a_{mn} \end{matrix} \right] 
    </me> and
    <me> B =  \left[ \begin{matrix} b_{11} \amp b_{12} \amp \cdots \amp b_{1n} \\ b_{21} \amp b_{22} \amp \cdots \amp b_{2n} \\ \vdots \amp \ddots \amp \amp \vdots \\ b_{m1} \amp b_{m2} \amp \cdots \amp b_{mn} \end{matrix} \right]
    </me> then
    <me> A + B =   \left[ \begin{matrix} a_{11} + b_{11} \amp a_{12} + b_{12}\amp \cdots \amp a_{1n} + b_{1n}\\ a_{21}+ b_{21} \amp a_{22}+ b_{22} \amp \cdots \amp a_{2n} + b_{2n}\\ \vdots \amp \ddots \amp \amp \vdots \\ a_{m1}+ b_{m1} \amp a_{m2}+ b_{m2} \amp \cdots \amp a_{mn}+ b_{mn} \end{matrix} \right]
    </me>
    Given a number <m>\lambda</m> in <m>K</m>, we can also multiply the entire matrix <m>A</m> by <m>\lambda</m> by just multiplying each entry by <m>\lambda</m> as in 
    <me>
        \lambda A = \left[ \begin{matrix} \lambda a_{11} \amp\lambda a_{12} \amp \cdots \amp\lambda a_{1n} \\ \lambda a_{21} \amp \lambda a_{22} \amp \cdots \amp \lambda a_{2n} \\ \vdots \amp \ddots \amp \amp \vdots \\ \lambda a_{m1} \amp \lambda a_{m2} \amp \cdots \amp \lambda a_{mn} \end{matrix} \right] 
    </me>
    This operation is called <term>scalar multiplication</term> of a matrix and generally plays a different role than matrix multiplication which we now define.</p>

    <definition xml:id="def-matrixproduct">
            <notation>
                <usage><m>A B</m></usage>
                <description>product of two matrices</description>
            </notation>
            <statement>
                <p>
                    Let <m>A = (a_{ij})</m> be an <m>m \times n</m> matrix and <m>B = (b_{jk})</m> an <m>n \times p</m> matrix. The <term>matrix product</term> <m>AB = C</m> is an <m>m \times p</m> matrix with <m>(i,k)</m>-th entry 
                        <me> c_{ik} = a_{i1}b_{1k} + a_{i2}b_{2k} + \cdots + a_{in} b_{nk}. </me>
                </p>
            </statement>
    </definition>

    <p>Note that the matrix product <m>AB</m> is only defined when the number of columns of <m>A</m> equals the number of rows of <m>B</m>.</p>

    <example>
        <title>Multiplying a row matrix by a column matrix</title>
        <statement>
            <p>
            Each entry of a matrix product is obtained by multiplying a row from the first matrix with a column from the second. For example, the product of the <m>1 \times 3</m> and <m>3 \times 1</m> matrix is just a number <me> \left[ \begin{matrix} -4 \amp 3 \amp 2 \end{matrix} \right] \left[ \begin{matrix}2 \\ 1 \\ -1 \end{matrix} \right] = (-4)\cdot 2 + 3 \cdot 1 + 2 \cdot (-1) = -7. </me> When writing <m>1 \times 1</m> matrices, we usually drop the left and right brackets.</p>
        </statement>
    </example>

    <example xml:id="exa-matrixarithmetic">
        <title>Arithmetic of square matrices</title>
        <statement>
            <p>
            Square matrices are matrices of size <m>n \times n</m>. For a fixed <m>n</m>, it is convenient to compute with such matrices because they can be added and multiplied without worrying about their size. For example,
            <md>
                <mrow>\left[ \begin{matrix} 1 \amp 4 \\ -1 \amp 1\end{matrix} \right] \left( \left[ \begin{matrix} 0 \amp 1 \\ 1 \amp 0\end{matrix} \right] + \left[ \begin{matrix} -1 \amp 1 \\ 3 \amp -2\end{matrix} \right] \right) \amp  = \left[ \begin{matrix} 1 \amp 4 \\ -1 \amp 1\end{matrix} \right] \left[ \begin{matrix} -1 \amp 2 \\ 4 \amp -2\end{matrix} \right],  </mrow>
                <mrow> \amp = \left[ \begin{matrix} 15 \amp -6 \\ 5 \amp -4\end{matrix} \right].</mrow>
            </md></p>
        </statement>
    </example>

    <example>
        <title>Identity matrices</title>
        <statement>
            <p>
            The<term>identity matrix</term> of size <m>n</m> is a square matrix given by
            <me>
                I_n  = \left[ \begin{matrix} 1 \amp 0 \amp \cdots \amp 0 \\ 0 \amp 1 \amp \ddots \amp \vdots \\ \vdots \amp \ddots \amp\ddots \amp 0 \\ 0 \amp \cdots \amp 0 \amp 1 \end{matrix} \right]. 
            </me>
            When <m>n</m> is clear from the context, we may write <m>I</m> instead of <m>I_n</m>. It is not hard to see that <m>I</m> acts as a multiplicative identity for matrix multiplication. More precisely, for <m>A</m> and <m>B</m> as above,
            <md>
                <mrow> A I_n \amp = A \amp I_n B \amp = B. </mrow>
            </md></p>
        </statement>
    </example>

    <p>At this point, let me encourage the student to use Sage to make matrix computations. The syntax for this can be picked up as you go, but we mention a few points. First, a matrix for Sage is a list of lists. Each member list is thought of as a row in the matrix, starting at the top and working down. Try changing a few of the numbers around, the size of the matrix to make sure you are comfortable defining matrices in Sage.
        <sage>
            <input>
                A = matrix([[1, 2],[-1, 3]])
                A
            </input>
            <output>
                [1   2]
                [-1  3]
            </output>
        </sage>
    Now, it is very good to know how to compute by hand, but once you feel comfortable with this, you ought to relax a bit and use your tools. Let's try <xref ref="exa-matrixarithmetic"/> with Sage. To do this, we will define each matrix separately and the write the expression we are trying to compute.
        <sage>
            <input>
                A = matrix([[1, 4],[-1, 1]])
                B = matrix([[0, 1],[1,0]])
                C = matrix([[-1,1],[3, -2]])
                A*(B + C)
            </input>
        <output>
            [15 -6]
            [5  -4]
        </output>
    </sage>
    </p>


    <p>Several of the arithmetic properties we reviewed in <xref ref="sec-arithmetic"/> still hold with addition and multiplication replaced with their matrix counterparts.
    </p>

    <proposition>
        <statement>
            Matrix arithmetic satisfies the properties
            <ol>
                <li> The matrix with all entries equal to zero is called the <term>zero matrix</term> and is an additive identity for matrix addition. All matrices have an additive inverse given by <m>-A = (-1)A</m> where the right hand side is scalar multiplication. The identity matrices act as multiplicative identities. </li> 
                <li> Both matrix addition and multiplication are associative operations when defined <md> <mrow> (A + B) + C \amp = A + (B + C) \amp (AB)C \amp = A(BC). </mrow></md> </li> 
                <li> Matrix addition is commutative <me> A + B = B + A, </me> </li> 
                <li> The distributive property holds when the operations are defined 
                <md> 
                <mrow>(A + B) C \amp = A C + BC \amp A(B + C) \amp = AB + AC. </mrow> </md> </li> 
            </ol>
        </statement>
    </proposition>

    <p>These properties can be shown to hold by a straightforward check, with perhaps the only intricate one being the associativity of the matrix product. However, this check is too messy for these notes and completely unenlightening, so we will leave it to the masochistic student's discretion. What is <em>most</em> interesting and important are the properties that are <em>not</em> listed above, namely the ones that fail.</p>

    <example>
        <title>Non-commuting matrices</title>
        <statement>
            <p>Note that <em>matrix multiplication is not commutative</em>. While occasionally two matrices will commute, even very simple looking matrices don't. For example
            <me>
                \left[ \begin{matrix} 0 \amp 1 \\ 0 \amp 0\end{matrix} \right]  \left[ \begin{matrix} 0 \amp 0 \\ 1 \amp 0\end{matrix} \right] = \left[ \begin{matrix} 1 \amp 0 \\ 0 \amp 0\end{matrix} \right],
            </me>
            but
            <me>
                \left[ \begin{matrix} 0 \amp 0 \\ 1 \amp 0\end{matrix} \right] \left[ \begin{matrix} 0 \amp 1 \\ 0 \amp 0\end{matrix} \right]   = \left[ \begin{matrix} 0 \amp 0 \\ 0 \amp 1\end{matrix} \right].
            </me>
            </p>
        </statement>
    </example>

    <example xml:id="exa-noninvertible">
        <title>Non-invertible matrices</title>
        <statement>
            <p>A general non-zero matrix does not have a multiplicative inverse. There are occasions where we can rule out an inverse on the basis of the size of a matrix. For example, we will show that only square matrices have the hope of being invertible (i.e. having a multiplicative inverse).  But even for a square matrix, this hope may be in vain. We can show this without any propositions or theorems by observing 
            <me>
                \left[ \begin{matrix} 1 \amp 1 \\ -1 \amp 1\end{matrix} \right]  \left[ \begin{matrix} 1 \amp 1 \\ 1 \amp 1\end{matrix} \right] = \left[ \begin{matrix} 0 \amp 0 \\ 0 \amp 0\end{matrix} \right].
            </me>
            On the left we have a product of two non-zero matrices and on the right we have the zero matrix. This is a pretty bizarre phenomenon if you have only ever worked with numbers because no two non-zero numbers have product zero! Now, if the first matrix had a multiplicative inverse <m>A</m>, then 
            <md>
                <mrow> \left[ \begin{matrix} 1 \amp 1 \\ 1 \amp 1\end{matrix} \right] \amp = I_2 \left[ \begin{matrix} 1 \amp 1 \\ 1 \amp 1\end{matrix} \right] </mrow>
                <mrow> \amp = \left( A \left[ \begin{matrix} 1 \amp -1 \\ -1 \amp 1\end{matrix} \right] \right) \left[ \begin{matrix} 1 \amp 1 \\ 1 \amp 1\end{matrix} \right] </mrow>
                <mrow> \amp = A \left(\left[ \begin{matrix} 1 \amp -1 \\ -1 \amp 1\end{matrix} \right]  \left[ \begin{matrix} 1 \amp 1 \\ 1 \amp 1\end{matrix} \right] \right) </mrow>
                <mrow> \amp = A \left[ \begin{matrix} 0 \amp 0 \\ 0 \amp 0\end{matrix} \right] </mrow>
                <mrow> \amp =  \left[ \begin{matrix} 0 \amp 0 \\ 0 \amp 0\end{matrix} \right] </mrow>
            </md>
            But of course, this is ridiculous, so indeed the first matrix has no inverse.
            </p>
        </statement>
    </example>

    <p>As we will see, matrices with multiplicative inverses play a central role in linear algebra. The computational criterion for the existence of an inverse and the algorithm or formula of the inverse are key results and techniques that every student should master.</p>
    
    <exercises xml:id="exe-matrices1">
        <exercise>
            <statement>
                <p> Give an example of a matrix <m>B</m> that has a left inverse, but not a right inverse. In otherwords, there exists a matrix <m>A</m> for which <m>AB = I</m> but <em>there is no</em> matrix <m>C</m> for which <m>BC = I</m>. </p>
            </statement>
            <hint> The size of the identity matrices <math>I</math> in the first and second equation may be different.</hint>
        </exercise>
        <exercise>
            <introduction><p> 
            Calculate the following matrices:
            </p>
            </introduction>
            <task>
                <statement>
                    <p>
                    <me>
                         \left[ \begin{matrix} 2 \amp 1 \\ - 2 \amp 0 \\ 1 \amp -1 \end{matrix} \right] \left[ \begin{matrix} 2 \amp 1 \amp 0 \\ 0 \amp 1 \amp 3 \end{matrix} \right]
                    </me>
                    </p>
                </statement>
            </task>
            <task>
                <statement>
                    <p>
                    <me>
                        \left[ \begin{matrix} 1 - i \amp 1 \\ 0 \amp i - 1  \end{matrix} \right] \left( \left[ \begin{matrix} i  \amp 0 \\ 0 \amp 1  \end{matrix} \right] + \left[ \begin{matrix} 1  \amp 0 \\ 0 \amp i  \end{matrix} \right] \right)
                    </me>
                    </p>
                </statement>
            </task>
        </exercise>
        
        <exercise>
            <statement>
                <p> Matrices do not need to have entries which are numbers. They can be functions as well. Calculate the following product as a <m>2 \times 1</m> matrix of polynomials.
                <me>
                         \left[ \begin{matrix} t + 2 \amp t - 1 \amp t  \\ 1 \amp t \amp 0 \end{matrix} \right] \left[ \begin{matrix} t \\ 1 \\ t - 1 \end{matrix} \right]
                </me>
                </p>
            </statement>
        </exercise> 
        <exercise>
            <statement>
                <p> 
                Explain why a <m>1 \times 3</m> matrix cannot be invertible. 
                </p>
            </statement>
            <hint>
            Show that for any such matrix <m>A</m>, there is <m>3 \times 1</m> matrix <m>B</m> which satisfies <m>AB = 0</m>. Then adapt the argument given in <xref ref="exa-noninvertible"/>.
            </hint>
        </exercise>
    </exercises>

</section>